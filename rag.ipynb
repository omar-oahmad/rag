{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9bacecff2a004269a876833b81d1926a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b887570034eb44b3b23d021f8cb008eb",
              "IPY_MODEL_ded168a3ed1a4524ab5125b2a26c1baf",
              "IPY_MODEL_c2c623d5c26f4e93b577d8b3abbccf46"
            ],
            "layout": "IPY_MODEL_bdce41c13e634c559154e2ff40be386e"
          }
        },
        "b887570034eb44b3b23d021f8cb008eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b02bd08a82441bb56498e51d1ee889",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a0ca5d795b4b7ab9130f5e6543797f",
            "value": ""
          }
        },
        "ded168a3ed1a4524ab5125b2a26c1baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c50c9e2bdd6497c99de0312346804a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fef5d0d1dbb24f6ca3f9f4a73607e1ad",
            "value": 1
          }
        },
        "c2c623d5c26f4e93b577d8b3abbccf46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3460bbd758ae4c7f90d0d0199773beb4",
            "placeholder": "​",
            "style": "IPY_MODEL_c3d2eebeb3e1431690a9c852e68e3854",
            "value": " 198/? [00:01&lt;00:00, 94.93it/s]"
          }
        },
        "bdce41c13e634c559154e2ff40be386e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56b02bd08a82441bb56498e51d1ee889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a0ca5d795b4b7ab9130f5e6543797f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c50c9e2bdd6497c99de0312346804a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fef5d0d1dbb24f6ca3f9f4a73607e1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3460bbd758ae4c7f90d0d0199773beb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d2eebeb3e1431690a9c852e68e3854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2X9hfLj66tI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0bc3b4-d7d3-4efa-efd6-654b70343798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Running in Google Colab, installing requirements.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.11\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-3.2.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.44.1\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.4.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=187309225 sha256=237ef9c6157db394e1ddde4ba609a21ebb98382377a27041edc09318801a6f24\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.6.3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "    print(\"[INFO] Running in Google Colab, installing requirements.\")\n",
        "    !pip install -U torch\n",
        "    !pip install PyMuPDF\n",
        "    !pip install tqdm\n",
        "    !pip install sentence-transformers\n",
        "    !pip install accelerate\n",
        "    !pip install bitsandbytes\n",
        "    !pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "pdf_path = \"gre_math_review.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_path):\n",
        "  print (\"downloading file\")\n",
        "  url = \"https://www.ets.org/pdfs/gre/gre-math-review.pdf\"\n",
        "  filename = pdf_path\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    with open(filename, \"wb\") as file:\n",
        "          file.write(response.content)\n",
        "    print(f\"The file has been downloaded and saved as {filename}\")\n",
        "  else:\n",
        "      print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "else:\n",
        "  print(f\"File {pdf_path} exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKvNxqpHQySf",
        "outputId": "9e84f2a2-ffc4-4c36-f2a5-83049e87d994"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading file\n",
            "The file has been downloaded and saved as gre_math_review.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def text_formatter(text: str) -> str:\n",
        "  \"\"\"text formatting\"\"\"\n",
        "  cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
        "  return cleaned_text\n",
        "\n",
        "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
        "    doc = fitz.open(pdf_path)\n",
        "    pages_and_texts = []\n",
        "    for page_number, page in tqdm(enumerate(doc)):\n",
        "        text = page.get_text()\n",
        "        text = text_formatter(text)\n",
        "        pages_and_texts.append({\"page_number\": page_number - 41,\n",
        "                                \"page_char_count\": len(text),\n",
        "                                \"page_word_count\": len(text.split(\" \")),\n",
        "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
        "                                \"page_token_count\": len(text) / 4,\n",
        "                                \"text\": text})\n",
        "    return pages_and_texts\n",
        "\n",
        "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
        "pages_and_texts[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "9bacecff2a004269a876833b81d1926a",
            "b887570034eb44b3b23d021f8cb008eb",
            "ded168a3ed1a4524ab5125b2a26c1baf",
            "c2c623d5c26f4e93b577d8b3abbccf46",
            "bdce41c13e634c559154e2ff40be386e",
            "56b02bd08a82441bb56498e51d1ee889",
            "f9a0ca5d795b4b7ab9130f5e6543797f",
            "8c50c9e2bdd6497c99de0312346804a0",
            "fef5d0d1dbb24f6ca3f9f4a73607e1ad",
            "3460bbd758ae4c7f90d0d0199773beb4",
            "c3d2eebeb3e1431690a9c852e68e3854"
          ]
        },
        "id": "a4kqjUjhQyPw",
        "outputId": "cf3ba06f-0957-493e-fa2c-0957e95b196d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bacecff2a004269a876833b81d1926a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': -41,\n",
              "  'page_char_count': 155,\n",
              "  'page_word_count': 24,\n",
              "  'page_sentence_count_raw': 1,\n",
              "  'page_token_count': 38.75,\n",
              "  'text': 'GRE® Verbal Reasoning  and Quantitative Reasoning  Sample Questions with Explanations  Math Review for the GRE General Test  Quantitative Reasoning measure'},\n",
              " {'page_number': -40,\n",
              "  'page_char_count': 1170,\n",
              "  'page_word_count': 194,\n",
              "  'page_sentence_count_raw': 12,\n",
              "  'page_token_count': 292.5,\n",
              "  'text': 'Overview This Math Review will familiarize you with the mathematical skills and concepts that are important  for solving problems and reasoning quantitatively on the Quantitative Reasoning measure of the  GRE® General Test. The skills and concepts are in the areas of Arithmetic, Algebra, Geometry, and  Data Analysis. The material covered includes many definitions, properties, and examples, as well as  a set of exercises (with answers) at the end of each part. Note, however, that this review is not intended  to be all-inclusive — the test may include some concepts that are not explicitly presented in this review. If any material in this review seems especially unfamiliar or is covered too briefly, you may also wish  to consult appropriate mathematics texts for more information. Another resource is the Khan Academy®  page on the GRE website at www.ets.org/gre/khan, where you will find links to free instructional videos  about concepts in this review. Copyright © 2024 by ETS. All rights reserved. ETS and GRE are registered trademarks of ETS. The Eight-Point  Logo is a trademark of ETS. KHAN ACADEMY is a registered trademark of Khan Academy, Inc. 685519960'}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.sample(pages_and_texts, k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zFyfLt6QyNa",
        "outputId": "0b07e331-1f05-460a-b10b-5b6698efb188"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': -15,\n",
              "  'page_char_count': 2035,\n",
              "  'page_word_count': 435,\n",
              "  'page_sentence_count_raw': 12,\n",
              "  'page_token_count': 508.75,\n",
              "  'text': 'GRE Math Review                             26      $1,300 $156 $1,456 + =   Because the final result is the sum of the initial investment (100% of $1,300) and the  increase (12% of $1,300), the final result is 100% 12% 112% + =  of $1,300. Thus,  another way to get the final result is to multiply the value of the investment by the  decimal equivalent of 112%, which is 1.12:  \\uf028 \\uf029\\uf028 \\uf029 $1,300 1.12 $1,456 \\uf03d   A quantity may have several successive percent changes, where the base of each  successive change is the result of the preceding percent change, as is the case in the  following example.  Example 1.7.16:  On September 1, 2013, the number of children enrolled in a certain  preschool was 8% less than the number of children enrolled at the preschool on  September 1, 2012. On September 1, 2014, the number of children enrolled in the  preschool was 6% greater than the number of children enrolled in the preschool on  September 1, 2013. By what percent did the number of students enrolled change from  September 1, 2012 to September 1, 2014?  Solution:  The initial base is the enrollment on September 1, 2012. The first percent  change was the 8% decrease in the enrollment from September 1, 2012, to  September 1, 2013. As a result of this decrease, the enrollment on September 1, 2013,  was ( ) 100 8 % − , or 92%, of the enrollment on September 1, 2012. The decimal  equivalent of 92% is 0.92.  So, if n represents the number of children enrolled on September 1, 2012, then the  number of children enrolled on September 1, 2013, is equal to 0.92 .n   The new base is the enrollment on September 1, 2013, which is 0.92 .n  The second  percent change was the 6% increase in enrollment from September 1, 2013, to  September 1, 2014. As a result of this increase, the enrollment on September 1, 2014, was  ( ) 100 6 %, +  or 106%, of the enrollment on September 1, 2013. The decimal equivalent  of 106% is 1.06.   Thus, the number of children enrolled on September 1, 2014, was ( )( ) 1.06 0.92 , n which  is equal to 0.9752 .n'},\n",
              " {'page_number': 19,\n",
              "  'page_char_count': 1236,\n",
              "  'page_word_count': 287,\n",
              "  'page_sentence_count_raw': 6,\n",
              "  'page_token_count': 309.0,\n",
              "  'text': 'GRE Math Review                             60      To find the value of P, we divide both sides of the equation by ( )3 1 0.035 . +   ( )3 $1,000 $902 1 0.035 P = ≈ +   Thus, to the nearest dollar, $902 should be invested.  Example 2.7.12:  A college student expects to earn at least $1,000 in interest on an  initial investment of $20,000. If the money is invested for one year at an annual interest  rate of r percent, compounded quarterly, what is the least annual interest rate that would  achieve the goal? (Give your answer to the nearest 0.1 percent.)  Solution:  According to the formula for r percent annual interest, compounded quarterly,  the value of the investment after 1 year is  ( ) 4 $20,000 1 400 r +   By setting this value greater than or equal to $21,000 and solving for r, we get   ( ) 4 $20,000 1 $21,000 400 r + ≥   which simplifies to  ( ) 4 1 1.05 400 r + ≥   We can use the fact that taking the positive fourth root of each side of an inequality  preserves the direction of the inequality. It is also true that taking the positive square root  or any other positive root of each side of an inequality preserves the direction of the  inequality. Using this fact, take the positive fourth root of both sides of'},\n",
              " {'page_number': -26,\n",
              "  'page_char_count': 1381,\n",
              "  'page_word_count': 355,\n",
              "  'page_sentence_count_raw': 8,\n",
              "  'page_token_count': 345.25,\n",
              "  'text': 'GRE Math Review                             15      ( ) ( ) ( ) ( ) 3 2 1 0 7 10 5 10 3 10 2 10 + + + +  \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 1 2 3 4 10 1 10 8 10 \\uf02d \\uf02d \\uf02d \\uf02b \\uf02b   If there are a finite number of digits to the right of the decimal point, converting a  decimal to an equivalent fraction with integers in the numerator and denominator is a  straightforward process. Since each place value is a power of 10, every decimal can be  converted to an integer divided by a power of 10. Here are three examples.  Example 1.4.1:   3 2.3 2 10 \\uf03d \\uf02b 20 3 23 10 10 10 \\uf03d \\uf02b \\uf03d   Example 1.4.2:   17 90.17 90 100 \\uf03d \\uf02b 9,000 17 9,017 100 100 \\uf02b \\uf03d \\uf03d   Example 1.4.3:   612 0.612 1,000 \\uf03d   Conversely, every fraction with integers in the numerator and denominator can be  converted to an equivalent decimal by dividing the numerator by the denominator using  long division (which is not in this review). The decimal that results from the long division  will either terminate, as in 1 0.25 4 \\uf03d  and 52 2.08, 25 \\uf03d  or repeat without end, as in  1 0.111..., 9 \\uf03d  1 0.0454545..., 22 \\uf03d   and 25 2.08333.... 12 \\uf03d  One way to indicate the  repeating part of a decimal that repeats without end is to use a bar over the digits that  repeat. Here are four examples of fractions converted to decimals.  Example 1.4.4:  3 0.375 8 \\uf03d   Example 1.4.5:  259 6.475 40 \\uf03d   Example 1.4.6:   1 0.3 3 \\uf02d \\uf03d\\uf02d   Example 1.4.7:  15 1.0714285 14 \\uf03d'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hZZKDICfQyK0",
        "outputId": "d75425eb-8a3f-4ef0-c09d-ded2bd4ecc02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
              "0          -41              155               24                        1   \n",
              "1          -40             1170              194                       12   \n",
              "2          -39             5193              252                       41   \n",
              "3          -38             2071              471                       30   \n",
              "4          -37             2452              560                       24   \n",
              "\n",
              "   page_token_count                                               text  \n",
              "0             38.75  GRE® Verbal Reasoning  and Quantitative Reason...  \n",
              "1            292.50  Overview This Math Review will familiarize you...  \n",
              "2           1298.25  GRE Math Review   2  Table of Contents  ARITHM...  \n",
              "3            517.75  GRE Math Review                             3 ...  \n",
              "4            613.00  GRE Math Review                             4 ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f135f1e-bf1b-46ea-b9cc-c40e1802308e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>page_char_count</th>\n",
              "      <th>page_word_count</th>\n",
              "      <th>page_sentence_count_raw</th>\n",
              "      <th>page_token_count</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-41</td>\n",
              "      <td>155</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>38.75</td>\n",
              "      <td>GRE® Verbal Reasoning  and Quantitative Reason...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-40</td>\n",
              "      <td>1170</td>\n",
              "      <td>194</td>\n",
              "      <td>12</td>\n",
              "      <td>292.50</td>\n",
              "      <td>Overview This Math Review will familiarize you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-39</td>\n",
              "      <td>5193</td>\n",
              "      <td>252</td>\n",
              "      <td>41</td>\n",
              "      <td>1298.25</td>\n",
              "      <td>GRE Math Review   2  Table of Contents  ARITHM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-38</td>\n",
              "      <td>2071</td>\n",
              "      <td>471</td>\n",
              "      <td>30</td>\n",
              "      <td>517.75</td>\n",
              "      <td>GRE Math Review                             3 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-37</td>\n",
              "      <td>2452</td>\n",
              "      <td>560</td>\n",
              "      <td>24</td>\n",
              "      <td>613.00</td>\n",
              "      <td>GRE Math Review                             4 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f135f1e-bf1b-46ea-b9cc-c40e1802308e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f135f1e-bf1b-46ea-b9cc-c40e1802308e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f135f1e-bf1b-46ea-b9cc-c40e1802308e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-011b5490-f761-40d3-bb69-4dc98449f70d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-011b5490-f761-40d3-bb69-4dc98449f70d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-011b5490-f761-40d3-bb69-4dc98449f70d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 198,\n  \"fields\": [\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57,\n        \"min\": -41,\n        \"max\": 156,\n        \"num_unique_values\": 198,\n        \"samples\": [\n          24,\n          73,\n          -25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 598,\n        \"min\": 124,\n        \"max\": 5193,\n        \"num_unique_values\": 188,\n        \"samples\": [\n          467,\n          2363,\n          1067\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111,\n        \"min\": 24,\n        \"max\": 590,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          178,\n          140,\n          185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_sentence_count_raw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 41,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          7,\n          5,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 149.56745587816906,\n        \"min\": 31.0,\n        \"max\": 1298.25,\n        \"num_unique_values\": 188,\n        \"samples\": [\n          116.75,\n          590.75,\n          266.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 198,\n        \"samples\": [\n          \"GRE Math Review                             65      The slope of a line passing through two points  ( ) 1 1 , Q x y  and  ( ) 2 2 , , R x y  where 1 2, x x \\u2260   is defined as  2 1 2 1 y y x x \\u2212 \\u2212   This ratio is often called \\u201crise over run,\\u201d where rise is the change in y when moving from  Q to R and run is the change in x when moving from Q to R. A horizontal line has a slope  of 0, since the rise is 0 for any two points on the line. Therefore, the equation of every  horizontal line has the form  , y b =  where b is the y-intercept. The slope of a vertical line  is not defined, since the run is 0. The equation of every vertical line has the form  , x a =   where a is the x-intercept.  Two lines are parallel if their slopes are equal. Two lines are perpendicular if their  slopes are negative reciprocals of each other. For example, the line with equation  2 5 y x = +  is perpendicular to the line with equation  1 9. 2 y x = \\u2212 +   Example 2.8.1:  Algebra Figure 3 below shows the graph of the line through the points  ( ) 2, 3 Q \\u2212 \\u2212  and  ( ) 4,1.5 . R\",\n          \"GRE Math Review                             114        Geometry Figure 30  The volume V of a right circular cylinder that has height h and a base with radius r is the  product of the height and the area of the base, or  2 V r h p \\uf03d   The surface area A of a right circular cylinder is the sum of the areas of the two bases  and the area of its lateral surface, or  \\uf028 \\uf029 2 2 2 A r rh p p \\uf03d \\uf02b   For example, if a right circular cylinder has height 6.5 and a base with radius 3, then its  volume is  \\uf028\\uf029\\uf028 \\uf029 2 3 6.5 58.5 V p p \\uf03d \\uf03d   and its surface area is  \\uf028\\uf029 \\uf028\\uf029\\uf028 \\uf029 2 2 3 2 3 6.5 57 A p p p \\uf03d \\uf02b \\uf03d\",\n          \"GRE Math Review                             16      Every fraction with integers in the numerator and denominator is equivalent to a decimal  that either terminates or repeats. That is, every rational number can be expressed as a  terminating or repeating decimal. The converse is also true; that is, every terminating or  repeating decimal represents a rational number.  Not all decimals are terminating or repeating; for instance, the decimal that is equivalent  to 2  is 1.41421356237..., and it can be shown that this decimal does not terminate or  repeat. Another example is 0.020220222022220222220..., which has groups of  consecutive 2s separated by a 0, where the number of 2s in each successive group  increases by one. Since these two decimals do not terminate or repeat, they are not  rational numbers. Such numbers are called irrational numbers.  1.5 Real Numbers  The set of real numbers consists of all rational numbers and all irrational numbers. The  real numbers include all integers, fractions, and decimals. The set of real numbers can be  represented by a number line called the real number line. Arithmetic Figure 2 below is a  number line.    Arithmetic Figure 2  Every real number corresponds to a point on the number line, and every point on the  number line corresponds to a real number. On the number line, all numbers to the left of  0 are negative and all numbers to the right of 0 are positive. As shown in  Arithmetic Figure 2, the negative numbers  0.4, \\uf02d  1, \\uf02d   3 , 2 \\uf02d  2, \\uf02d   5, \\uf02d   and 3 \\uf02d are to the  left of 0, and the positive numbers 1 , 2  1, 2,  2, 2.6, and 3 are to the right of 0. Only the  number 0 is neither negative nor positive.  A real number x is less than a real number y if x is to the left of y on the number line,  which is written as  . x y \\uf03c  A real number y is greater than a real number x if y is to the\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "WM0JsLJ2QyIY",
        "outputId": "5ad8435f-2cb5-49a1-a79c-c095b241f585"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
              "count       198.00           198.00           198.00                   198.00   \n",
              "mean         57.50          1145.67           277.54                     9.64   \n",
              "std          57.30           598.27           111.42                     5.53   \n",
              "min         -41.00           124.00            24.00                     1.00   \n",
              "25%           8.25           764.50           204.00                     6.00   \n",
              "50%          57.50          1159.50           274.00                     9.00   \n",
              "75%         106.75          1409.75           341.50                    12.00   \n",
              "max         156.00          5193.00           590.00                    41.00   \n",
              "\n",
              "       page_token_count  \n",
              "count            198.00  \n",
              "mean             286.42  \n",
              "std              149.57  \n",
              "min               31.00  \n",
              "25%              191.12  \n",
              "50%              289.88  \n",
              "75%              352.44  \n",
              "max             1298.25  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41e9bf7a-b46c-4ef3-b001-380f65c58fe9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>page_char_count</th>\n",
              "      <th>page_word_count</th>\n",
              "      <th>page_sentence_count_raw</th>\n",
              "      <th>page_token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>198.00</td>\n",
              "      <td>198.00</td>\n",
              "      <td>198.00</td>\n",
              "      <td>198.00</td>\n",
              "      <td>198.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>57.50</td>\n",
              "      <td>1145.67</td>\n",
              "      <td>277.54</td>\n",
              "      <td>9.64</td>\n",
              "      <td>286.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>57.30</td>\n",
              "      <td>598.27</td>\n",
              "      <td>111.42</td>\n",
              "      <td>5.53</td>\n",
              "      <td>149.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-41.00</td>\n",
              "      <td>124.00</td>\n",
              "      <td>24.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>31.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.25</td>\n",
              "      <td>764.50</td>\n",
              "      <td>204.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>191.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.50</td>\n",
              "      <td>1159.50</td>\n",
              "      <td>274.00</td>\n",
              "      <td>9.00</td>\n",
              "      <td>289.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>106.75</td>\n",
              "      <td>1409.75</td>\n",
              "      <td>341.50</td>\n",
              "      <td>12.00</td>\n",
              "      <td>352.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>156.00</td>\n",
              "      <td>5193.00</td>\n",
              "      <td>590.00</td>\n",
              "      <td>41.00</td>\n",
              "      <td>1298.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41e9bf7a-b46c-4ef3-b001-380f65c58fe9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41e9bf7a-b46c-4ef3-b001-380f65c58fe9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41e9bf7a-b46c-4ef3-b001-380f65c58fe9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dff13b69-882c-438d-839d-dcffe3fd734b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dff13b69-882c-438d-839d-dcffe3fd734b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dff13b69-882c-438d-839d-dcffe3fd734b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.03005327236153,\n        \"min\": -41.0,\n        \"max\": 198.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          198.0,\n          57.5,\n          106.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1629.3283508764102,\n        \"min\": 124.0,\n        \"max\": 5193.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1145.67,\n          1159.5,\n          198.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 169.18071130767663,\n        \"min\": 24.0,\n        \"max\": 590.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          277.54,\n          274.0,\n          198.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_sentence_count_raw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 66.88798940606388,\n        \"min\": 1.0,\n        \"max\": 198.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          9.64,\n          9.0,\n          198.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 395.8931147959726,\n        \"min\": 31.0,\n        \"max\": 1298.25,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          286.42,\n          289.88,\n          198.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import\n",
        "from spicy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "doc = nlp(\"This is a sentence. This another sentence.\")\n",
        "assert len(list(doc.sents)) == 2\n",
        "\n",
        "list(doc.sents)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "SSJ8k8PmQyGA",
        "outputId": "36c1d387-3e03-4d37-ffc0-e156e7052361"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'spicy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-06c2f2177481>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentencizer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is a sentence. This another sentence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spicy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in tqdm(pages_and_texts):\n",
        "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
        "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
        "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
      ],
      "metadata": {
        "id": "qa9XQbu3Qx_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.sample(pages_and_texts, k=1)"
      ],
      "metadata": {
        "id": "e4_rtl0jQx9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "BR1H3m2JQx7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_sentence_chunk_size = 10\n",
        "def split_list(input_list: list,\n",
        "               slice_size: int) -> list[list[str]]:\n",
        "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
        "for item in tqdm(pages_and_texts):\n",
        "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
        "                                         slice_size=num_sentence_chunk_size)\n",
        "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])\n",
        "\n",
        "random.sample(pages_and_texts, k=1)"
      ],
      "metadata": {
        "id": "28QMYVjnQx5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "cOvyrzAZTaLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "pages_and_chunks = []\n",
        "for item in tqdm(pages_and_texts):\n",
        "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
        "        chunk_dict = {}\n",
        "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
        "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
        "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo\n",
        "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
        "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
        "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
        "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
        "\n",
        "        pages_and_chunks.append(chunk_dict)\n",
        "\n",
        "len(pages_and_chunks)\n"
      ],
      "metadata": {
        "id": "C057X15OQx2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.sample(pages_and_chunks, k=1)"
      ],
      "metadata": {
        "id": "loKJgM44Qx06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pages_and_chunks)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "VwOji_xnQxyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_token_length = 30\n",
        "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
        "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
      ],
      "metadata": {
        "id": "zDuZX8UdQxsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
        "pages_and_chunks_over_min_token_len[:2]"
      ],
      "metadata": {
        "id": "qlBw7TAxTsWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
        "                                      device=\"cpu\")\n",
        "sentences = [\n",
        "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
        "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
        "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
        "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
        "]\n",
        "\n",
        "embeddings = embedding_model.encode(sentences)\n",
        "embeddings_dict = dict(zip(sentences, embeddings))\n",
        "\n",
        "for sentence, embedding in embeddings_dict.items():\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", embedding)\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "f-q07_i6TsUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_sentence = \"Yo! How cool are embeddings?\"\n",
        "single_embedding = embedding_model.encode(single_sentence)\n",
        "print(f\"Sentence: {single_sentence}\")\n",
        "print(f\"Embedding:\\n{single_embedding}\")\n",
        "print(f\"Embedding size: {single_embedding.shape}\")"
      ],
      "metadata": {
        "id": "Jw_hcBc5TsSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "embedding_model.to(\"cpu\")\n",
        "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
        "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
      ],
      "metadata": {
        "id": "m-e_s0aZTsQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]"
      ],
      "metadata": {
        "id": "90EBkLERTsO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
        "                                               batch_size=32,\n",
        "                                               convert_to_tensor=True)\n",
        "\n",
        "text_chunk_embeddings"
      ],
      "metadata": {
        "id": "eWDxcvQTTsM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
        "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
        "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
      ],
      "metadata": {
        "id": "NUPTV0XPTsK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
        "text_chunks_and_embedding_df_load.head()"
      ],
      "metadata": {
        "id": "NFYl_nFHTsI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
        "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
        "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
        "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "8m6YApqfTsG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks_and_embedding_df.head()\n",
        "embeddings[0]"
      ],
      "metadata": {
        "id": "PkEQ-aNOTsEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util, SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
        "                                      device=device)"
      ],
      "metadata": {
        "id": "9oa60_k_TsAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"fractions and decimals\"\n",
        "print(f\"Query: {query}\")\n",
        "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "from time import perf_counter as timer\n",
        "\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
        "top_results_dot_product"
      ],
      "metadata": {
        "id": "tslg6c1FUSvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "larger_embeddings = torch.randn(100*embeddings.shape[0], 768).to(device)\n",
        "print(f\"Embeddings shape: {larger_embeddings.shape}\")\n",
        "\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(a=query_embedding, b=larger_embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Time take to get scores on {len(larger_embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")"
      ],
      "metadata": {
        "id": "KHIwkhvYUSti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def print_wrapped(text, wrap_length=80):\n",
        "    wrapped_text = textwrap.fill(text, wrap_length)\n",
        "    print(wrapped_text)"
      ],
      "metadata": {
        "id": "trfwK8YbUSrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query: '{query}'\\n\")\n",
        "print(\"Results:\")\n",
        "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    print(\"Text:\")\n",
        "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
        "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "UERZ_nopUSpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "pdf_path = \"gre_math_review.pdf\"\n",
        "doc = fitz.open(pdf_path)\n",
        "page = doc.load_page(5 + 41)\n",
        "\n",
        "img = page.get_pixmap(dpi=300)\n",
        "\n",
        "\n",
        "doc.close()\n",
        "\n",
        "img_array = np.frombuffer(img.samples_mv,\n",
        "                          dtype=np.uint8).reshape((img.h, img.w, img.n))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(13, 10))\n",
        "plt.imshow(img_array)\n",
        "plt.title(f\"Query: '{query}' | Most relevant page:\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lnOpkOO_USn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def dot_product(vector1, vector2):\n",
        "    return torch.dot(vector1, vector2)\n",
        "\n",
        "def cosine_similarity(vector1, vector2):\n",
        "    dot_product = torch.dot(vector1, vector2)\n",
        "\n",
        "    norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
        "    norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
        "\n",
        "    return dot_product / (norm_vector1 * norm_vector2)\n",
        "\n",
        "vector1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "vector2 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "vector3 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
        "vector4 = torch.tensor([-1, -2, -3], dtype=torch.float32)\n",
        "\n",
        "print(\"Dot product between vector1 and vector2:\", dot_product(vector1, vector2))\n",
        "print(\"Dot product between vector1 and vector3:\", dot_product(vector1, vector3))\n",
        "print(\"Dot product between vector1 and vector4:\", dot_product(vector1, vector4))\n",
        "\n",
        "print(\"Cosine similarity between vector1 and vector2:\", cosine_similarity(vector1, vector2))\n",
        "print(\"Cosine similarity between vector1 and vector3:\", cosine_similarity(vector1, vector3))\n",
        "print(\"Cosine similarity between vector1 and vector4:\", cosine_similarity(vector1, vector4))"
      ],
      "metadata": {
        "id": "-EPJIeKjUSls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_resources(query: str,\n",
        "                                embeddings: torch.tensor,\n",
        "                                model: SentenceTransformer=embedding_model,\n",
        "                                n_resources_to_return: int=5,\n",
        "                                print_time: bool=True):\n",
        "    \"\"\"\n",
        "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    query_embedding = model.encode(query,\n",
        "                                   convert_to_tensor=True)\n",
        "\n",
        "    start_time = timer()\n",
        "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
        "    end_time = timer()\n",
        "\n",
        "    if print_time:\n",
        "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "    scores, indices = torch.topk(input=dot_scores,\n",
        "                                 k=n_resources_to_return)\n",
        "\n",
        "    return scores, indices\n",
        "\n",
        "def print_top_results_and_scores(query: str,\n",
        "                                 embeddings: torch.tensor,\n",
        "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
        "                                 n_resources_to_return: int=5):\n",
        "    \"\"\"\n",
        "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
        "\n",
        "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
        "    \"\"\"\n",
        "\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings,\n",
        "                                                  n_resources_to_return=n_resources_to_return)\n",
        "\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    print(\"Results:\")\n",
        "    for score, index in zip(scores, indices):\n",
        "        print(f\"Score: {score:.4f}\")\n",
        "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
        "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "lcwX7OWUU9Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what are the divisibility rules of 1,2,3,4 and 5\"\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ],
      "metadata": {
        "id": "Pd51_cEFU9SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_top_results_and_scores(query=query,\n",
        "                             embeddings=embeddings)"
      ],
      "metadata": {
        "id": "JJaXTsaMU9P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
        "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
        "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
      ],
      "metadata": {
        "id": "wYVFTI0nU9Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if gpu_memory_gb < 5.1:\n",
        "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
        "elif gpu_memory_gb < 8.1:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
        "    use_quantization_config = True\n",
        "    model_id = \"google/gemma-2b-it\"\n",
        "elif gpu_memory_gb < 19.0:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
        "    use_quantization_config = False\n",
        "    model_id = \"google/gemma-2b-it\"\n",
        "elif gpu_memory_gb > 19.0:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
        "    use_quantization_config = False\n",
        "    model_id = \"google/gemma-7b-it\"\n",
        "\n",
        "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
        "print(f\"model_id set to: {model_id}\")"
      ],
      "metadata": {
        "id": "6Sn-6h2cVRRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.utils import is_flash_attn_2_available\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                         bnb_4bit_compute_dtype=torch.float16)\n",
        "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
        "  attn_implementation = \"flash_attention_2\"\n",
        "else:\n",
        "  attn_implementation = \"sdpa\"\n",
        "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
        "\n",
        "model_id = model_id\n",
        "print(f\"[INFO] Using model_id: {model_id}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
        "\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id,\n",
        "                                                 torch_dtype=torch.float16,\n",
        "                                                 quantization_config=quantization_config if use_quantization_config else None,\n",
        "                                                 low_cpu_mem_usage=False,\n",
        "                                                 attn_implementation=attn_implementation)\n",
        "if not use_quantization_config:\n",
        "    llm_model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Hdn44tQzVROT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model"
      ],
      "metadata": {
        "id": "8JHB2CDGVRMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_num_params(model: torch.nn.Module):\n",
        "    return sum([param.numel() for param in model.parameters()])\n",
        "\n",
        "get_model_num_params(llm_model)"
      ],
      "metadata": {
        "id": "Ct9ySJfqVRJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_mem_size(model: torch.nn.Module):\n",
        "\n",
        "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
        "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
        "\n",
        "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
        "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
        "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
        "\n",
        "    return {\"model_mem_bytes\": model_mem_bytes,\n",
        "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
        "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
        "\n",
        "get_model_mem_size(llm_model)"
      ],
      "metadata": {
        "id": "Hb1Mgs6eVRH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"What are permutations and combinations\"\n",
        "print(f\"Input text:\\n{input_text}\")\n",
        "\n",
        "dialogue_template = [\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": input_text}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                       tokenize=False,\n",
        "                                       add_generation_prompt=True)\n",
        "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
      ],
      "metadata": {
        "id": "YKiuSbLxVsGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
        "outputs = llm_model.generate(**input_ids,\n",
        "                             max_new_tokens=256)\n",
        "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
      ],
      "metadata": {
        "id": "aG0-xgkHVRFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_decoded = tokenizer.decode(outputs[0])\n",
        "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
      ],
      "metadata": {
        "id": "OCc6yPwyVQ_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input text: {input_text}\\n\")\n",
        "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
      ],
      "metadata": {
        "id": "i_4DfQ9QV8t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt4_questions = [\n",
        "    \"What are ratios\",\n",
        "    \"Rules for lines and angles\",\n",
        "    \"Describe three dimensional figures\",\n",
        "]\n",
        "\n",
        "manual_questions = [\n",
        "    \"Explain the counting methods\",\n",
        "    \"What are numerical methods for describing data?\",\n",
        "    \"Types of Probability Distributions\",\n",
        "]\n",
        "\n",
        "query_list = gpt4_questions + manual_questions"
      ],
      "metadata": {
        "id": "CR010kTnV8rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "query = random.choice(query_list)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ],
      "metadata": {
        "id": "ZlFGnBBNV8pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ehNOTM8V8nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxaiHdyGV8ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wHXjaN0FV8ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-GT8miDV8gY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}